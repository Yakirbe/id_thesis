% Chapter 1

\chapter{Time Complexity} % Main chapter title

\label{Chapter6} 
%----------------------------------------------------------------------------------------
Time complexity for each step of the $IDDND$ function building is displayed in this section. 
Learning / training timing was excluded and will be discussed at chapter \ref{Chapter8}


\section{Discretization}

	Discretization implementation is not specified in this paper since we are using a OTS method such $k-means$ clustering algorithm, although This step may be applied by various methods. 
	The common ones are k-means or their variation. Here we refer to $k-means$ \cite{kmeans} based methods.
	Even though the problem of finding the global optimum of the $k-means$ objective function:
	
	\begin{equation}
	arg\min_s\sum_{i=1}^{k} \sum_{x_j \in S_i}^{}\|x_j - \mu_i \|^2
	\end{equation}
	
	is NP-hard[]. \\
	
	However, running a fixed number i of iterations of the standard algorithm consumes only: \\ \\ \\
	\textbf{$O(i \dot k \dot n \dot d)$} \\ \\
	Where:
	i - convergence iterations \\
	k - number of means \\
	N - dataset samples \\
	n - object dimension \\
    
    for n points in d dimensions
	

\section{Interpolation}

As described above \ref{Chapter3}, we divide the interpolation phase time complexity for several phases:




\section{Find the bounding hypercube}

	Find a given vectorâ€™s bounding box is actually find a bounding pair for each element in this vector. Since the means vectors are sorted then this step takes n times (for n dimensions) $log(n)$ , which is the time complexity for binary search. In total, time complexity of this step is $O(nlog(n))$
	\break


\section{Find the bounding simplex}


Finding the bounding simplex is equivalent to find an obeying permutation over the given vector.
Time complexity for this step is therefore: $O(nlog(n))$\\. While using common sorting algorithms such Quicksort \cite{quicksort}/Merge Sort\cite{mergesort}/Timsort\cite{peters2002timsort}.


\section{ID coefficients extraction}

In the step, we take in matter only the second attitude shown above since it is faster.
Computing the coefficients is also possible in $O(n)$.
We can compute the first index in $O(n)$ and do additional $O(n)$ updates each with a time complexity of $O(1)$ for computing the other indices, so in total this step take only $O(n)$.

total time complexity for the interpolation step method is: \\

$ O(nlog(n)) + O(nlog(n)) + O(n) = O(nlog(n)) $


\section{Assigning}

Data assigning of the sparse vector is purely flattening a matrix into a vector shape, which takes $O(1)$ \ref{fig:33}


