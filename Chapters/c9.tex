% Chapter 1

\chapter{Conclusions and discussion} % Main chapter title

\label{Chapter9} 

\section{Summary}

In this work we have proposed a new embedding method for a single vector and for a pair
of vectors. This embedding method enables: 
\begin{enumerate}
	\item efficient classification and regression of functions of single vectors
	\item efficient approximation of distance functions
	\item general, non-Euclidean, semimetric learning
\end{enumerate}.
For the best of our knowledge, this is the first work that enables learning any general, non-Euclidean, semimetrics.\\ 
That is, our method is a universal semimetric learning and approximation method that can approximate any distance function with as high accuracy as needed with or without semimetric constraints.\\
In this work, we have displayed a detailed exploration of our $ID$ method, describing its basic classification/regression algorithmic flow for objects embedding and its applications options.\\

We have described how it may be applied on pair objects matters, such similarity/dissimilarity problems \ref{Chapter3}.\\

Also described how to apply our method on single objects embedding problems, for cases such classification/regression problems \ref{Chapter4}.\\

On chapter \ref{Chapter5}, the learning phase of the embedding method was described, detailing a specific adaptation to SGD \cite{SGD} algorithm in order to fit our data types to optimize the optimization process of loss convergence.\\

Chapter \ref{Chapter6} handles the time complexity issues related to the embedded objects. Each step in the process is analyzed in terms of current complexity analysis of the general method.\\

Chapter \ref{Chapter7} handles the memory issues related to the embedded objects, which are originally sparsed, and how it may be treated in order to save memory.\\

Chapter \ref{Chapter8} examines our $IDD$ method on e test case displayed by \cite{perp_color}, which studies method to observe perceptual colors difference. Here we have validated the correctness of our method by displaying out-scoring results in comparison to original articles results.

\break
\section{further exploration}

This work displays a continuous non-linear embedding method for any desired classification/regression task. In chapter \ref{Chapter8} we displayed an accuracy exploration of our method, on the object pairs embedding scenario. \vskip10pt
In addition to this examination, the following objectives may be observed:

\begin{itemize}
	\item \textbf{various centers per dimension} may be a good valuation of the optimal condition per problem, in case cross validation may treat single dimension at a time. By optimizing several dimensions in one shot, one can decide of a fixed number of centers for all dimensions, which may be still optimized in matters of accuracy, time and memory.
	\item \textbf{Memory} consumption may be observed among various embedding method include ours, while using our memory saving tips at chapter \ref{Chapter6}, where in our method (and in \cite{perp_color}, number of centers/clusters is a valid argument to parameterize in this kind of comparison)
	\item \textbf{time} complexity may also taken in comparison among various object-embedding methods, while using our chapter \ref{Chapter7} theories.
	\item \textbf{end-to-end application embedding} such image segmentation as shown in \cite{perp_color}, may assist evaluating this method
	\item \textbf{single objects embedding} may also be inspected for some classification/regression task, again with all parameters mentioned above (accuracy, time, memory)
\end{itemize}

